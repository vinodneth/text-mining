x<-0
rm(list=ls())
setwd("C:/Users/vinod.nethilath/OneDrive - Accenture/TextMining/text-mining")
#Set Options
options(stringsAsFactors=F) ## default setting
library(stringi)
library(stringr)
library(qdap)
library(tm)
library(lda)
library(GuardianR)
library(LDAvis)
library(car)
library(treemap)
library(pbapply)
library(data.table)
library(text2vec)
text<-fread('Airbnb-boston_only.csv')
airbnb<-data.table(review_id=text$review_id,comments=text$comments,review_scores_rating=text$review_scores_rating)
airbnb$comments<-removeWords(airbnb$comments,c(stopwords('en'),'Boston'))
airbnb$comments<-removePunctuation(airbnb$comments)
airbnb$comments<-stripWhitespace(airbnb$comments)
airbnb$comments<-removeNumbers(airbnb$comments)
airbnb$comments<-tolower(airbnb$comments)
tokens <-strsplit(airbnb$comments,split = " ", fixed = T)
vocab <-create_vocabulary(itoken(tokens),ngram = c(1,1))
vocab <-prune_vocabulary(vocab,term_count_min = 5)
vocab[[1]][221:225]
vocab[221:225]
vocab[221:225,]
iter <- itokens(tokens)
iter <- itoken(tokens)
vectorizer<-vocab_vectorizer(vocab,grow_dtm = F, skip_grams_Window = 5)
?vocab_vectorizer
vectorizer<-vocab_vectorizer(vocab)
vectorizer<-vocab_vectorizer(vocab) ##,grow_dtm = F, skip_grams_Window = 5)
tcm<-create_tcm(iter,vectorizer)
str(tcm)
ip <- as.data.frame(installed.packages()[,c(1,3:4)])
rownames(ip) <- NULL
ip <- ip[is.na(ip$Priority),1:2,drop=FALSE]
write.csv(ip,"PkgList.csv")
